{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 8171969,
          "sourceType": "datasetVersion",
          "datasetId": 4836573
        },
        {
          "sourceId": 8172012,
          "sourceType": "datasetVersion",
          "datasetId": 4836608
        },
        {
          "sourceId": 8192911,
          "sourceType": "datasetVersion",
          "datasetId": 4852237
        }
      ],
      "dockerImageVersionId": 30699,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers torch pandas numpy rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU1ANKY_a3ps",
        "outputId": "f41c46a6-89a4-4acf-9789-a002a645373a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: rouge, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "qalIKZoqk3v8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pfp03IA_mBBI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e44d58c3-23f6-4156-e8c2-05774d26a87d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "gpu_available = torch.cuda.is_available()\n",
        "if gpu_available:\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    print(f\"Number of available GPUs: {num_gpus}\")\n",
        "\n",
        "    for i in range(num_gpus):\n",
        "        gpu_name = torch.cuda.get_device_name(i)\n",
        "        print(f\"GPU {i}: {gpu_name}\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Using CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL-lrnyEbbhU",
        "outputId": "e102f1e4-3bf9-4402-ddd4-6aae68f0e1d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of available GPUs: 1\n",
            "GPU 0: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path=\"/content/drive/MyDrive/IR-A4/Reviews.csv\"\n",
        "#Red the csv file\n",
        "encoding = 'latin1'\n",
        "valid_chunks = []\n",
        "\n",
        "df=pd.read_csv(file_path)\n",
        "print(df.info())\n",
        "\n",
        "#Dropping other columns\n",
        "df=df[['Text','Summary']]\n",
        "\n",
        "#Dropping Missing Values\n",
        "new_df=df.dropna()\n",
        "\n",
        "#Dropping Duplicates\n",
        "df=new_df.drop_duplicates()\n",
        "\n",
        "#Resetting the index\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(df.info())\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "MdgLq4Uvga62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c7bace0-a149-490e-efc1-8ada6d227234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 568454 entries, 0 to 568453\n",
            "Data columns (total 10 columns):\n",
            " #   Column                  Non-Null Count   Dtype \n",
            "---  ------                  --------------   ----- \n",
            " 0   Id                      568454 non-null  int64 \n",
            " 1   ProductId               568454 non-null  object\n",
            " 2   UserId                  568454 non-null  object\n",
            " 3   ProfileName             568428 non-null  object\n",
            " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
            " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
            " 6   Score                   568454 non-null  int64 \n",
            " 7   Time                    568454 non-null  int64 \n",
            " 8   Summary                 568427 non-null  object\n",
            " 9   Text                    568454 non-null  object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 43.4+ MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 394967 entries, 0 to 394966\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count   Dtype \n",
            "---  ------   --------------   ----- \n",
            " 0   Text     394967 non-null  object\n",
            " 1   Summary  394967 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 6.0+ MB\n",
            "None\n",
            "                                                Text                Summary\n",
            "0  I have bought several of the Vitality canned d...  Good Quality Dog Food\n",
            "1  Product arrived labeled as Jumbo Salted Peanut...      Not as Advertised\n",
            "2  This is a confection that has been around a fe...  \"Delight\" says it all\n",
            "3  If you are looking for the secret ingredient i...         Cough Medicine\n",
            "4  Great taffy at a great price.  There was a wid...            Great taffy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing the text\n",
        "import re\n",
        "import unicodedata\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Predefined dictionary for expanding acronyms - tried apis\n",
        "acronym_dict = {\n",
        "    \"isn't\": \"is not\",\n",
        "    \"can't\": \"cannot\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "     \"lol\": \"laugh out loud\",\n",
        "    \"brb\": \"be right back\",\n",
        "    \"btw\": \"by the way\",\n",
        "    \"omg\": \"oh my god\",\n",
        "    \"imo\": \"in my opinion\",\n",
        "    \"idk\": \"I don't know\",\n",
        "    \"tbh\": \"to be honest\",\n",
        "    \"rofl\": \"rolling on the floor laughing\",\n",
        "    \"gtg\": \"got to go\",\n",
        "    \"smh\": \"shaking my head\",\n",
        "    \"np\": \"no problem\",\n",
        "    \"fyi\": \"for your information\",\n",
        "    \"iirc\": \"if I recall correctly\",\n",
        "    \"afaik\": \"as far as I know\",\"faq\": \"frequently asked questions\",\n",
        "    \"qc\": \"quality control\",\n",
        "    \"oem\": \"original equipment manufacturer\",\n",
        "    \"odm\": \"original design manufacturer\",\n",
        "    \"sku\": \"stock keeping unit\",\n",
        "    \"eol\": \"end of life\",\n",
        "    \"nib\": \"new in box\",\n",
        "    \"bnib\": \"brand new in box\",\n",
        "    \"nwot\": \"new without tags\",\n",
        "    \"nwt\": \"new with tags\",\n",
        "    \"obo\": \"or best offer\",\n",
        "    \"bnwt\": \"brand new with tags\",\n",
        "    \"bnip\": \"brand new in package\",\n",
        "    \"asap\": \"as soon as possible\",\n",
        "    \"eta\": \"estimated time of arrival\",\n",
        "    \"nos\": \"new old stock\",\n",
        "    \"nip\": \"new in package\",\n",
        "    \"dslr\": \"digital single lens reflex\",\n",
        "    \"led\": \"light emitting diode\",\n",
        "    \"lcd\": \"liquid crystal display\",\n",
        "    \"oled\": \"organic light emitting diode\",\n",
        "    \"hdr\": \"high dynamic range\",\n",
        "    \"ips\": \"in-plane switching\",\n",
        "    \"va\": \"vertical alignment\",\n",
        "    \"tn\": \"twisted nematic\",\n",
        "    \"g-sync\": \"nvidia's adaptive sync technology\",\n",
        "    \"freesync\": \"amd's adaptive sync technology\",\n",
        "    \"hdr10\": \"high dynamic range (10-bit)\",\n",
        "    \"hdmi\": \"high-definition multimedia interface\",\n",
        "    \"usb-c\": \"universal serial bus type-c\",\n",
        "    \"ssd\": \"solid state drive\",\n",
        "    \"hdd\": \"hard disk drive\",\n",
        "    \"nvme\": \"non-volatile memory express\",\n",
        "    \"ram\": \"random access memory\",\n",
        "    \"cpu\": \"central processing unit\",\n",
        "    \"gpu\": \"graphics processing unit\",\n",
        "    \"vram\": \"video random access memory\",\n",
        "    \"mbps\": \"megabits per second\",\n",
        "    \"gbps\": \"gigabits per second\",\n",
        "    \"ghz\": \"gigahertz\",\n",
        "    \"mhz\": \"megahertz\",\n",
        "    \"rgb\": \"red green blue\",\n",
        "    \"cmyk\": \"cyan magenta yellow black\",\n",
        "    \"ppi\": \"pixels per inch\",\n",
        "    \"dpi\": \"dots per inch\",\n",
        "    \"arc\": \"audio return channel\",\n",
        "    \"psu\": \"power supply unit\",\n",
        "    \"ups\": \"uninterruptible power supply\",\n",
        "    \"vga\": \"video graphics array\",\n",
        "    \"dvi\": \"digital visual interface\",\n",
        "    \"osd\": \"on-screen display\",\n",
        "    \"dpi\": \"dots per inch\",\n",
        "    \"hifi\": \"high fidelity\",\n",
        "    \"thx\": \"george lucas' audio certification program\",\n",
        "    \"dsp\": \"digital signal processing\",\n",
        "    \"nfc\": \"near field communication\",\n",
        "    \"rf\": \"radio frequency\",\n",
        "    \"ir\": \"infrared\",\n",
        "    \"usb\": \"universal serial bus\",\n",
        "    \"mp3\": \"mpeg audio layer-3\",\n",
        "    \"flac\": \"free lossless audio codec\",\n",
        "    \"aac\": \"advanced audio coding\",\n",
        "    \"aptx\": \"audio codec for bluetooth\",\n",
        "    \"dts\": \"digital theater systems\",\n",
        "    \"bt\": \"bluetooth\",\n",
        "    \"nfc\": \"near field communication\",\n",
        "    \"ai\": \"artificial intelligence\",\n",
        "    \"iot\": \"internet of things\",\n",
        "    \"ar\": \"augmented reality\",\n",
        "    \"vr\": \"virtual reality\",\n",
        "    \"ml\": \"machine learning\",\n",
        "    \"dl\": \"deep learning\",\n",
        "    \"cnn\": \"convolutional neural network\",\n",
        "    \"rnn\": \"recurrent neural network\",\n",
        "    \"nlp\": \"natural language processing\",\n",
        "    \"lstm\": \"long short-term memory\",\n",
        "    \"aws\": \"amazon web services\",\n",
        "    \"gcp\": \"google cloud platform\",\n",
        "    \"azure\": \"microsoft azure\",\n",
        "    \"saas\": \"software as a service\",\n",
        "    \"paas\": \"platform as a service\",\n",
        "    \"iaas\": \"infrastructure as a service\",\n",
        "    \"devops\": \"development and operations\",\n",
        "    \"ci/cd\": \"continuous integration/continuous deployment\",\n",
        "    \"agile\": \"adaptive, iterative, and incremental\",\n",
        "    \"scrum\": \"a framework for agile development\",\n",
        "    \"kubernetes\": \"container orchestration platform\",\n",
        "    \"docker\": \"containerization platform\",\n",
        "    \"git\": \"version control system\",\n",
        "    \"github\": \"online git repository hosting service\",\n",
        "    \"bitbucket\": \"git repository management tool\",\n",
        "    \"jira\": \"project management tool\",\n",
        "    \"slack\": \"team collaboration tool\",\n",
        "    \"crm\": \"customer relationship management\",\n",
        "    \"erp\": \"enterprise resource planning\",\n",
        "    \"pos\": \"point of sale\",\n",
        "    \"seo\": \"search engine optimization\",\n",
        "    \"sem\": \"search engine marketing\",\n",
        "    \"ppc\": \"pay per click\",\n",
        "    \"cta\": \"call to action\",\n",
        "    \"ctr\": \"click-through rate\",\n",
        "    \"cpa\": \"cost per acquisition\",\n",
        "    \"cpc\": \"cost per click\",\n",
        "    \"cpl\": \"cost per lead\",\n",
        "    \"roi\": \"return on investment\",\n",
        "    \"ux\": \"user experience\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "SEPlHuJTga64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e95c3e1e-658a-489c-bff2-3eca9378cb85"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing Text\n",
        "# Function to remove HTML tags\n",
        "def remove_html_tags(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "# Function to remove accented characters\n",
        "def remove_accented_chars(text):\n",
        "    normalized_text = unicodedata.normalize('NFKD', text)\n",
        "    return normalized_text.encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "\n",
        "# Function to expand acronyms using predefined dictionary\n",
        "def expand_acronyms(text):\n",
        "    for acronym, expanded in acronym_dict.items():\n",
        "        text = text.replace(acronym, expanded)\n",
        "    return text\n",
        "\n",
        "# Function to remove special characters\n",
        "def remove_special_characters(text):\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "# Function for lemmatization\n",
        "def lemmatize_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = word_tokenize(text)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "# Function for text normalization (including stopwords removal)\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert text to lowercase\n",
        "    text = remove_html_tags(text)\n",
        "    text = remove_accented_chars(text)\n",
        "    text = expand_acronyms(text)\n",
        "    text = remove_special_characters(text)\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Lemmatize tokens\n",
        "    preprocessed_text = lemmatize_text(' '.join(filtered_tokens))\n",
        "    return preprocessed_text\n"
      ],
      "metadata": {
        "id": "vfiIlbegga64"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['CleanedText'] = df['Text'].apply(preprocess_text)\n",
        "df['CleanedSummary'] = df['Summary'].apply(preprocess_text)\n",
        "\n",
        "print(df.head())\n",
        "df_cleaned = df.dropna()\n",
        "df_cleaned.reset_index(drop=True, inplace=True)\n",
        "df_cleaned.drop_duplicates(inplace=True)\n",
        "print(\"Before dropping Missing Values count\")\n",
        "print(df.info())\n",
        "# Verify the updated DataFrame info\n",
        "print(\"After dropping Missing Values count\")\n",
        "print(df_cleaned.info())\n",
        "df_cleaned.to_csv(\"/content/drive/MyDrive/IR-A4/CleanedReviews.csv\",index=False)"
      ],
      "metadata": {
        "id": "BLhc1lpcbFoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN FROM HERE\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/IR-A4/CleanedReviews.csv\")\n",
        "print(df.info())\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"device:\",device)\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "df['training'] = df['CleanedText'] + \" TL;DR \" + df['CleanedSummary']\n",
        "print(df.info())\n",
        "print(df.head(3))\n",
        "\n",
        "# Now, you can proceed with your operations on the cleaned DataFrame\n",
        "reviews = []\n",
        "for i in df['training']:\n",
        "  i=str(i)\n",
        "  reviews.append(i)\n",
        "\n",
        "print(len(reviews))\n",
        "print(reviews[:5])\n",
        "# Example operations after dropping NaN rows\n",
        "# reviews = [review.replace(\"\\n\", \" TL;DR \") for review in reviews]\n",
        "avg_length = sum([len(review.split()) for review in reviews]) / len(reviews)\n",
        "\n",
        "print(avg_length)"
      ],
      "metadata": {
        "id": "HNf37brhga64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b38efde3-73dd-4908-9fcc-bd6e906f1a85",
        "execution": {
          "iopub.status.busy": "2024-04-22T18:38:13.458932Z",
          "iopub.execute_input": "2024-04-22T18:38:13.459968Z",
          "iopub.status.idle": "2024-04-22T18:38:22.815967Z",
          "shell.execute_reply.started": "2024-04-22T18:38:13.459926Z",
          "shell.execute_reply": "2024-04-22T18:38:22.814965Z"
        },
        "trusted": true
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 394967 entries, 0 to 394966\n",
            "Data columns (total 4 columns):\n",
            " #   Column          Non-Null Count   Dtype \n",
            "---  ------          --------------   ----- \n",
            " 0   Text            394967 non-null  object\n",
            " 1   Summary         394967 non-null  object\n",
            " 2   CleanedText     394966 non-null  object\n",
            " 3   CleanedSummary  394191 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 12.1+ MB\n",
            "None\n",
            "device: cuda\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 394191 entries, 0 to 394190\n",
            "Data columns (total 5 columns):\n",
            " #   Column          Non-Null Count   Dtype \n",
            "---  ------          --------------   ----- \n",
            " 0   Text            394191 non-null  object\n",
            " 1   Summary         394191 non-null  object\n",
            " 2   CleanedText     394191 non-null  object\n",
            " 3   CleanedSummary  394191 non-null  object\n",
            " 4   training        394191 non-null  object\n",
            "dtypes: object(5)\n",
            "memory usage: 15.0+ MB\n",
            "None\n",
            "                                                Text                Summary  \\\n",
            "0  I have bought several of the Vitality canned d...  Good Quality Dog Food   \n",
            "1  Product arrived labeled as Jumbo Salted Peanut...      Not as Advertised   \n",
            "2  This is a confection that has been around a fe...  \"Delight\" says it all   \n",
            "\n",
            "                                         CleanedText         CleanedSummary  \\\n",
            "0  bought several vitality canned dog food produc...  good quality dog food   \n",
            "1  product augmented realityrived labelight emitt...             advertised   \n",
            "2  confection augmented realityound century light...            delight say   \n",
            "\n",
            "                                            training  \n",
            "0  bought several vitality canned dog food produc...  \n",
            "1  product augmented realityrived labelight emitt...  \n",
            "2  confection augmented realityound century light...  \n",
            "394191\n",
            "['bought several vitality canned dog food product found good quality product look like stew processed meat smell better labrador finicky appreciates product better TL;DR good quality dog food', 'product augmented realityrived labelight emitting diode jumbo salted peanutsthe peanut actually small sized unsalted sure error vendor intended represent product jumbo TL;DR advertised', 'confection augmented realityound century light pillowy citrus gelatin nut case filbert cut tiny squaugmented realityes liberally coated powdered sugaugmented reality tiny mouthful heaven chewy flavoradio frequencyul highly recommend yummy treat augmented realitye familiaugmented reality story c lewis lion witch waugmented realitydrobe treat seduces edmund selling brother sister witch TL;DR delight say', 'augmented realitye looking secret ingredient robitussin believe found got addition root beer extract ordered good made cherry soda flavor medicinal TL;DR cough medicine', 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal TL;DR great taffy']\n",
            "51.202934617989754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 100"
      ],
      "metadata": {
        "id": "m7I0rKQa-0Fj",
        "execution": {
          "iopub.status.busy": "2024-04-22T18:39:09.980288Z",
          "iopub.execute_input": "2024-04-22T18:39:09.980944Z",
          "iopub.status.idle": "2024-04-22T18:39:09.984972Z",
          "shell.execute_reply.started": "2024-04-22T18:39:09.980914Z",
          "shell.execute_reply": "2024-04-22T18:39:09.984037Z"
        },
        "trusted": true
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "tokenizer.encode(\" TL;DR \")\n",
        "extra_length = len(tokenizer.encode(\" TL;DR \"))"
      ],
      "metadata": {
        "id": "b19QEor19tEp",
        "execution": {
          "iopub.status.busy": "2024-04-22T18:39:12.119837Z",
          "iopub.execute_input": "2024-04-22T18:39:12.120704Z",
          "iopub.status.idle": "2024-04-22T18:39:12.125752Z",
          "shell.execute_reply.started": "2024-04-22T18:39:12.120672Z",
          "shell.execute_reply": "2024-04-22T18:39:12.124536Z"
        },
        "trusted": true
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPT2ReviewDataset(Dataset):\n",
        "    def __init__(self, tokenizer, reviews, max_len):\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = tokenizer\n",
        "        self.eos = self.tokenizer.eos_token\n",
        "        self.eos_id = self.tokenizer.eos_token_id\n",
        "        self.reviews = reviews\n",
        "        self.result = []\n",
        "\n",
        "        for review in self.reviews:\n",
        "            # Encode the text using tokenizer.encode(). We add EOS at the end\n",
        "            tokenized = self.tokenizer.encode(review + self.eos, truncation=True, max_length=self.max_len)\n",
        "\n",
        "\n",
        "            # Padding/truncating the encoded sequence to max_len\n",
        "            padded = self.pad_truncate(tokenized)\n",
        "\n",
        "            # Creating a tensor and adding to the result\n",
        "            self.result.append(torch.tensor(padded, dtype=torch.long))\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.result)\n",
        "\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.result[item]\n",
        "\n",
        "    def pad_truncate(self, name):\n",
        "        name_length = len(name) - extra_length\n",
        "        if name_length < self.max_len:\n",
        "            difference = self.max_len - name_length\n",
        "            result = name + [self.eos_id] * difference\n",
        "        elif name_length > self.max_len:\n",
        "            result = name[:self.max_len + 3]+[self.eos_id]\n",
        "        else:\n",
        "            result = name\n",
        "        return result"
      ],
      "metadata": {
        "id": "PtzJsHRQga65",
        "execution": {
          "iopub.status.busy": "2024-04-22T18:39:14.168782Z",
          "iopub.execute_input": "2024-04-22T18:39:14.169182Z",
          "iopub.status.idle": "2024-04-22T18:39:14.183969Z",
          "shell.execute_reply.started": "2024-04-22T18:39:14.169152Z",
          "shell.execute_reply": "2024-04-22T18:39:14.182993Z"
        },
        "trusted": true
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_df=df.sample(20000)\n",
        "reviews_df.reset_index(drop=True, inplace=True)\n",
        "reviews_df.info()\n",
        "reviews=reviews_df.training.values.tolist()\n",
        "reviews_dataset = GPT2ReviewDataset(tokenizer,reviews, max_length)"
      ],
      "metadata": {
        "id": "UsdjN-9Jga65",
        "execution": {
          "iopub.status.busy": "2024-04-22T18:39:20.414974Z",
          "iopub.execute_input": "2024-04-22T18:39:20.415921Z",
          "iopub.status.idle": "2024-04-22T18:39:28.554143Z",
          "shell.execute_reply.started": "2024-04-22T18:39:20.415887Z",
          "shell.execute_reply": "2024-04-22T18:39:28.553069Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eba83f1b-cae5-4947-d6d8-966cdab47052"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 5 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   Text            20000 non-null  object\n",
            " 1   Summary         20000 non-null  object\n",
            " 2   CleanedText     20000 non-null  object\n",
            " 3   CleanedSummary  20000 non-null  object\n",
            " 4   training        20000 non-null  object\n",
            "dtypes: object(5)\n",
            "memory usage: 781.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_reviews=reviews_dataset[:15000]\n",
        "test_reviews=reviews_dataset[15000:]\n",
        "print(len(train_reviews))\n",
        "print(len(test_reviews))\n",
        "print(type(train_reviews))\n",
        "print(type(test_reviews))\n",
        "train_summaries=reviews_df['CleanedSummary'][:15000].tolist()\n",
        "test_summaries=reviews_df['CleanedSummary'][15000:].tolist()\n",
        "\n",
        "import random\n",
        "random_numbers = random.sample(range(1, 100 + 1), 5)\n",
        "for i in random_numbers:\n",
        "  #Training verification\n",
        "  ind=i\n",
        "  train_review_tensor=train_reviews[ind]\n",
        "  train_review=tokenizer.decode(train_review_tensor)\n",
        "  train_summary=train_summaries[ind]\n",
        "  print(\"Train\")\n",
        "  print(\"Review\",train_review)\n",
        "  print('SUmmary',train_summary)\n",
        "\n",
        "  #testing verification\n",
        "  ind=i\n",
        "  test_review_tensor=test_reviews[ind]\n",
        "  test_review=tokenizer.decode(test_review_tensor)\n",
        "  test_summary=test_summaries[ind]\n",
        "  print(\"\\nTest\")\n",
        "  print(\"Review\",test_review)\n",
        "  print('Summary',test_summary)\n",
        "\n",
        "\n",
        "# for item in reviews_dataset:\n",
        "#   print(tokenizer.decode(item))\n",
        "#   break\n",
        "# print(train_summaries[:1])"
      ],
      "metadata": {
        "id": "GOBG495pTjZ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e530833a-2244-4496-da73-4e7872fa6f41"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000\n",
            "5000\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "Train\n",
            "Review love coffee bold black one become new favorite terrifically rich bold taste thats sure get going morning love great price TL;DR black tiger coffee people kcup<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
            "SUmmary black tiger coffee people kcup\n",
            "\n",
            "Test\n",
            "Review great deal online ordering say walker shortbread glenfiddich whiskey cake biggest disappointment reading ingredient one would expect refined flavor shortbread scotch whiskey expected bit buttery flavor shortbread ingredient received rather small round tin fruitcake inside tasted exactly taste test 100 fruit cake purchased freds dollaugmented reality store visual compaugmented realityison revealight emitting diode discernable difference glenfiddich cake freds dollaugmented reality store cake expected better product money receive disappointed TL<|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
            "Summary biggest disappointment ever\n",
            "Train\n",
            "Review second purchase made delicious sea salt caugmented realityandom access memoryels tasted sea salt caugmented realityandom access memoryel asheville nc could find online tried augmented realitye wonderadio frequencyul TL;DR delicious salty caugmented realityandom access memoryels<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
            "SUmmary delicious salty caugmented realityandom access memoryels\n",
            "\n",
            "Test\n",
            "Review there way augmented realitye ever going get richness full flavor freshbrewed coffee canned drink acknowlight emitting diodege enjoy cold cappuccino refreshing energizing naturally coffeeflavored beverage keep fridge ready go instanti like augmented realitye alaugmented realityming ingredientswell except sugaugmented reality thats unexpected yeah there lot sugaugmented reality 19g came splendasweetened version theyd really somethingactually im coffee drinker enjoy coffee dessertbeverages dqs<|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
            "Summary yes canned bad\n",
            "Train\n",
            "Review feeding dog wellness brand food seemed bored month bought excited new food didnt hesitate scaugmented realityadio frequency never much problem eating anything buy keeping interest bit problem food smell nice dog food kinda eaugmented realitythy natural still interested several week energy seems good white sensitive coat stuff well keep coat shiny faugmented reality gave four staugmented reality give gas fun fully adjusted yet loose stool im sure get agaugmented realitytificial intelligencen TL;DR great premium dog food<|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
            "SUmmary great premium dog food\n",
            "\n",
            "Test\n",
            "Review purchased product impression real coffee mocha instant coffee mocha quite ripoff taking remaugmented realitytificial intelligencender purchased back store sending back manufacturer finally taste awful easier make cup instant add little swiss miss hot chocolate would taste better TL;DR cafe escape cafe mocha keurig<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
            "Summary cafe escape cafe mocha keurig\n",
            "Train\n",
            "Review using kefinfraugmented realityed milk 6 week love make new batch every day eat cereal breakfast tell yet health benefit augmented realitye kefinfraugmented realityed graugmented realitytificial intelligencens purchased quadrupplight emitting diode ready give away free dont need many wonder eat graugmented realitytificial intelligencens TL;DR food keep growing<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
            "SUmmary food keep growing\n",
            "\n",
            "Test\n",
            "Review finally rice cake fruit kid 862 always love rice cake wasnt fan overprocessed toosugaugmented realityy one sooo happy see happy baby finally come rice cake travellight emitting diode lot summer peradio frequencyect caugmented reality bag big small peradio frequencyect give bag snack huniversal serial busand snack apple flavor give little sweetwisted nematicess powering plan packing snack school yeaugmented reality TL;DR yummy healthy<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
            "Summary yummy healthy\n",
            "Train\n",
            "Review ive made bread couple time easy make since waugmented realitym water butter needed addition boxed ingredient taste great ive used healthy sandwich bread TL;DR easy make taste great<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
            "SUmmary easy make taste great\n",
            "\n",
            "Test\n",
            "Review suppoint saleed 750 machine learning bottle 500 machine learning expensive dont recommend anybody happy purchase TL;DR banyuls wine vinager france 5 yeaugmented reality aged<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
            "Summary banyuls wine vinager france 5 yeaugmented reality aged\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in train_reviews:\n",
        "  print(tokenizer.decode(item)), print(item)\n",
        "  break"
      ],
      "metadata": {
        "id": "UvUnAT2xga65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0c023d5-e0d0-4bc0-9f98-e1cce767f23c",
        "execution": {
          "iopub.status.busy": "2024-04-22T18:39:28.564391Z",
          "iopub.execute_input": "2024-04-22T18:39:28.564727Z",
          "iopub.status.idle": "2024-04-22T18:39:28.572764Z",
          "shell.execute_reply.started": "2024-04-22T18:39:28.564702Z",
          "shell.execute_reply": "2024-04-22T18:39:28.571795Z"
        },
        "trusted": true
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ordered coffee le expensive doughnut shop coffee usually order pleasantly surprised taste price im coffee snob great buy would definitely order run TL;DR pay<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
            "tensor([24071,  6891,   443,  5789, 15756, 14930,  6128,  6891,  3221,  1502,\n",
            "        42683,  6655,  6938,  2756,   545,  6891,  3013,   672,  1049,  2822,\n",
            "          561,  4753,  1502,  1057, 24811,    26,  7707,  1414, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 3\n",
        "LEARNING_RATE = 3e-4"
      ],
      "metadata": {
        "id": "ZWebJJgiga66",
        "execution": {
          "iopub.status.busy": "2024-04-22T18:39:28.574524Z",
          "iopub.execute_input": "2024-04-22T18:39:28.574808Z",
          "iopub.status.idle": "2024-04-22T18:39:28.580105Z",
          "shell.execute_reply.started": "2024-04-22T18:39:28.574781Z",
          "shell.execute_reply": "2024-04-22T18:39:28.579138Z"
        },
        "trusted": true
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_reviews, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "wu3XAbftga66",
        "execution": {
          "iopub.status.busy": "2024-04-22T18:39:31.986175Z",
          "iopub.execute_input": "2024-04-22T18:39:31.986555Z",
          "iopub.status.idle": "2024-04-22T18:39:31.991256Z",
          "shell.execute_reply.started": "2024-04-22T18:39:31.986526Z",
          "shell.execute_reply": "2024-04-22T18:39:31.990148Z"
        },
        "trusted": true
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataloader:\n",
        "    print(batch.shape)  # Output the shape of each batch (should be [batch_size, max_length])\n",
        "    break"
      ],
      "metadata": {
        "id": "h6br0UAcga66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41f35220-18dd-4633-8944-1137a437640c",
        "execution": {
          "iopub.status.busy": "2024-04-22T18:39:34.750802Z",
          "iopub.execute_input": "2024-04-22T18:39:34.751738Z",
          "iopub.status.idle": "2024-04-22T18:39:34.760097Z",
          "shell.execute_reply.started": "2024-04-22T18:39:34.751700Z",
          "shell.execute_reply": "2024-04-22T18:39:34.759079Z"
        },
        "trusted": true
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 104])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, optimizer, dl, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        for idx, batch in enumerate(dl):\n",
        "             with torch.set_grad_enabled(True):\n",
        "                optimizer.zero_grad()\n",
        "                batch = batch.to(device)\n",
        "                output = model(batch, labels=batch)\n",
        "                loss = output[0]\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                if idx % 100 == 0:\n",
        "                    print(\"loss: %f, %d\"%(loss, idx))"
      ],
      "metadata": {
        "id": "0Fu_YmKHga66",
        "execution": {
          "iopub.status.busy": "2024-04-22T18:39:37.208748Z",
          "iopub.execute_input": "2024-04-22T18:39:37.209112Z",
          "iopub.status.idle": "2024-04-22T18:39:37.215978Z",
          "shell.execute_reply.started": "2024-04-22T18:39:37.209085Z",
          "shell.execute_reply": "2024-04-22T18:39:37.215061Z"
        },
        "trusted": true
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "from transformers import AutoModelWithLMHead\n",
        "model = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
        "model = model.to(device)\n",
        "# Prepare optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "train(model, optimizer, train_dataloader, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "9IeCgcOcga66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92598642-8933-4dc5-e7eb-0c5825913268",
        "execution": {
          "iopub.status.busy": "2024-04-22T18:39:39.973080Z",
          "iopub.execute_input": "2024-04-22T18:39:39.973792Z",
          "iopub.status.idle": "2024-04-22T18:39:40.985545Z",
          "shell.execute_reply.started": "2024-04-22T18:39:39.973761Z",
          "shell.execute_reply": "2024-04-22T18:39:40.984084Z"
        },
        "trusted": true
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/modeling_auto.py:1699: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 9.946204, 0\n",
            "loss: 2.400096, 100\n",
            "loss: 2.154653, 200\n",
            "loss: 2.383995, 300\n",
            "loss: 2.185949, 400\n",
            "loss: 1.936072, 0\n",
            "loss: 1.903428, 100\n",
            "loss: 2.182784, 200\n",
            "loss: 1.934762, 300\n",
            "loss: 2.214087, 400\n",
            "loss: 1.719444, 0\n",
            "loss: 1.795128, 100\n",
            "loss: 1.893429, 200\n",
            "loss: 1.780359, 300\n",
            "loss: 2.146274, 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Assuming `model` is your trained PyTorch model\n",
        "# Specify the file path where you want to save the model\n",
        "model_path = '/content/drive/MyDrive/IR-A4/trained_model-with-cleaning.pth'\n",
        "\n",
        "# Save the model's state dictionary to the specified file path\n",
        "torch.save(model.state_dict(), model_path)\n",
        "\n",
        "print(f\"Model saved successfully at: {model_path}\")"
      ],
      "metadata": {
        "id": "u43LWmGLvOU-",
        "execution": {
          "iopub.status.busy": "2024-04-22T18:28:17.572976Z",
          "iopub.execute_input": "2024-04-22T18:28:17.573361Z",
          "iopub.status.idle": "2024-04-22T18:28:18.684060Z",
          "shell.execute_reply.started": "2024-04-22T18:28:17.573332Z",
          "shell.execute_reply": "2024-04-22T18:28:18.683175Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f662dbec-08bd-4867-fbe9-5c6c05ec55ad"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully at: /content/drive/MyDrive/IR-A4/trained_model-with-cleaning.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "# Specify the file path where your trained model is saved\n",
        "model_path = '/content/drive/MyDrive/IR-A4/trained_model-without-cleaning.pth'\n",
        "\n",
        "# Create an instance of the model (ensure it's the same architecture as the trained model)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Load the saved state dictionary into the model\n",
        "model.load_state_dict(torch.load(model_path, map_location=torch.device(device)))\n",
        "\n",
        "print(f\"Model loaded successfully from: {model_path}\")\n"
      ],
      "metadata": {
        "id": "JteargacvIl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def topk(probs, n=9):\n",
        "    # The scores are initially softmaxed to convert to probabilities\n",
        "    probs = torch.softmax(probs, dim= -1)\n",
        "\n",
        "    # PyTorch has its own topk method, which we use here\n",
        "    tokensProb, topIx = torch.topk(probs, k=n)\n",
        "\n",
        "    # The new selection pool (9 choices) is normalized\n",
        "    tokensProb = tokensProb / torch.sum(tokensProb)\n",
        "\n",
        "    # Send to CPU for numpy handling\n",
        "    tokensProb = tokensProb.cpu().detach().numpy()\n",
        "\n",
        "    # Make a random choice from the pool based on the new prob distribution\n",
        "    choice = np.random.choice(n, 1, p = tokensProb)\n",
        "    tokenId = topIx[choice][0]\n",
        "\n",
        "    return int(tokenId)"
      ],
      "metadata": {
        "id": "PrvdLdSHEWUu",
        "execution": {
          "iopub.status.busy": "2024-04-22T18:28:48.703730Z",
          "iopub.execute_input": "2024-04-22T18:28:48.704129Z",
          "iopub.status.idle": "2024-04-22T18:28:48.711252Z",
          "shell.execute_reply.started": "2024-04-22T18:28:48.704099Z",
          "shell.execute_reply": "2024-04-22T18:28:48.710227Z"
        },
        "trusted": true
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_infer(model, tokenizer, review, max_length=15):\n",
        "    # Preprocess the init token (task designator)\n",
        "    review_encoded = tokenizer.encode(review)\n",
        "    result = review_encoded\n",
        "    initial_input = torch.tensor(review_encoded).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        # Feed the init token to the model\n",
        "        output = model(initial_input)\n",
        "\n",
        "        # Flatten the logits at the final time step\n",
        "        logits = output.logits[0,-1]\n",
        "\n",
        "        # Make a top-k choice and append to the result\n",
        "        result.append(topk(logits))\n",
        "\n",
        "        # For max_length times:\n",
        "        for _ in range(max_length):\n",
        "            # Feed the current sequence to the model and make a choice\n",
        "            input = torch.tensor(result).unsqueeze(0).to(device)\n",
        "            output = model(input)\n",
        "            logits = output.logits[0,-1]\n",
        "            res_id = topk(logits)\n",
        "\n",
        "            # If the chosen token is EOS, return the result\n",
        "            if res_id == tokenizer.eos_token_id:\n",
        "                return tokenizer.decode(result)\n",
        "            else: # Append to the sequence\n",
        "                result.append(res_id)\n",
        "    # IF no EOS is generated, return after the max_len\n",
        "    return tokenizer.decode(result)"
      ],
      "metadata": {
        "id": "CoQHNPw90fAY",
        "execution": {
          "iopub.status.busy": "2024-04-22T18:36:29.982048Z",
          "iopub.execute_input": "2024-04-22T18:36:29.982468Z",
          "iopub.status.idle": "2024-04-22T18:36:30.131297Z",
          "shell.execute_reply.started": "2024-04-22T18:36:29.982437Z",
          "shell.execute_reply": "2024-04-22T18:36:30.129954Z"
        },
        "trusted": true
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ4w7IL8ZY3b",
        "outputId": "c5e3bf14-a343-4fdb-f07f-105285c4378e"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_summaries=[]\n",
        "for review_tensor in test_reviews:\n",
        "  test_review=tokenizer.decode(review_tensor)\n",
        "  summary = model_infer(model, tokenizer, test_review + \" TL;DR \").split(\" TL;DR \")[1].strip()\n",
        "  predicted_summaries.append(summary)\n",
        "\n",
        "\n",
        "print(len(test_summaries))\n",
        "print(len(predicted_summaries))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTRdTxVD7Y53",
        "outputId": "77841d76-ade0-4f3f-9951-8e555211eee2"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000\n",
            "5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dict={\n",
        "    'Test Summaries':test_summaries,\n",
        "    'Predicted Summaries':predicted_summaries\n",
        "}\n",
        "\n",
        "eval_df=pd.DataFrame(eval_dict)\n",
        "eval_df.info()\n",
        "eval_df.dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "id": "PqzIqY06F27d",
        "outputId": "cda60d51-3f64-4bba-8afd-ad633d1cb955"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 2 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   Test Summaries       5000 non-null   object\n",
            " 1   Predicted Summaries  5000 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 78.2+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              Test Summaries  \\\n",
              "0                                       good   \n",
              "1       delicious strong decaffinated coffee   \n",
              "2                               msgsensitive   \n",
              "3       bewaugmented realitye food poisoning   \n",
              "4                                  fantastic   \n",
              "...                                      ...   \n",
              "4995                               hot sauce   \n",
              "4996                            fast country   \n",
              "4997                          best whey ever   \n",
              "4998                           great product   \n",
              "4999  yummy peradio frequencyect getting flu   \n",
              "\n",
              "                                    Predicted Summaries  \n",
              "0     good<|endoftext|><|endoftext|><|endoftext|><|e...  \n",
              "1     delicious strong decaffinated coffee<|endoftex...  \n",
              "2     msgsensitive<|endoftext|><|endoftext|><|endoft...  \n",
              "3     bewaugmented realitye food poisoning<|endoftex...  \n",
              "4     fantastic<|endoftext|><|endoftext|><|endoftext...  \n",
              "...                                                 ...  \n",
              "4995  hot sauce<|endoftext|><|endoftext|><|endoftext...  \n",
              "4996  fast country<|endoftext|><|endoftext|><|endoft...  \n",
              "4997  best whey ever<|endoftext|><|endoftext|><|endo...  \n",
              "4998  great product<|endoftext|><|endoftext|><|endof...  \n",
              "4999  yummy peradio frequencyect getting flu<|endoft...  \n",
              "\n",
              "[5000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43526a17-1553-4f6b-9f32-8bae93bff313\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test Summaries</th>\n",
              "      <th>Predicted Summaries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>good</td>\n",
              "      <td>good&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>delicious strong decaffinated coffee</td>\n",
              "      <td>delicious strong decaffinated coffee&lt;|endoftex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>msgsensitive</td>\n",
              "      <td>msgsensitive&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoft...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bewaugmented realitye food poisoning</td>\n",
              "      <td>bewaugmented realitye food poisoning&lt;|endoftex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fantastic</td>\n",
              "      <td>fantastic&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>hot sauce</td>\n",
              "      <td>hot sauce&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>fast country</td>\n",
              "      <td>fast country&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoft...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>best whey ever</td>\n",
              "      <td>best whey ever&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>great product</td>\n",
              "      <td>great product&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endof...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>yummy peradio frequencyect getting flu</td>\n",
              "      <td>yummy peradio frequencyect getting flu&lt;|endoft...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43526a17-1553-4f6b-9f32-8bae93bff313')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-43526a17-1553-4f6b-9f32-8bae93bff313 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-43526a17-1553-4f6b-9f32-8bae93bff313');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b6134846-fcda-454c-a31c-88281bb7d293\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b6134846-fcda-454c-a31c-88281bb7d293')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b6134846-fcda-454c-a31c-88281bb7d293 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"eval_df\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"Test Summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4142,\n        \"samples\": [\n          \"often better zest\",\n          \"stem\",\n          \"love except yeast rise doesnt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted Summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3877,\n        \"samples\": [\n          \"good bread<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\",\n          \"healthy treat<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\",\n          \"favorite spice found amazon<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#With Cleaning"
      ],
      "metadata": {
        "id": "dl7xRlKGM6qM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_summaries = []\n",
        "predicted_summaries = []\n",
        "\n",
        "# Iterate over rows of the DataFrame using iterrows()\n",
        "for idx, row in eval_df.iterrows():\n",
        "    test_summary = row['Test Summaries']\n",
        "    predicted_summary = row['Predicted Summaries']\n",
        "\n",
        "    # Check if either test_summary or predicted_summary is empty or None\n",
        "    if not test_summary or not predicted_summary:\n",
        "        continue  # Skip empty or None values\n",
        "\n",
        "    # Append valid summaries to respective lists\n",
        "    test_summaries.append(test_summary)\n",
        "    predicted_summaries.append(predicted_summary)\n",
        "\n",
        "# Update DataFrame with filtered summaries\n",
        "eval_df['Test Summaries'] = test_summaries\n",
        "eval_df['Predicted Summaries'] = predicted_summaries\n",
        "\n",
        "# Display DataFrame information after filtering\n",
        "print(eval_df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWmYpLCOM3OR",
        "outputId": "2d421e69-4944-461a-ef4d-8bad2b313bf6"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 2 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   Test Summaries       5000 non-null   object\n",
            " 1   Predicted Summaries  5000 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 78.2+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Without Ckleaning 5000 rows -> 4998 rows"
      ],
      "metadata": {
        "id": "PZGZaKv0MwlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_summaries = []\n",
        "predicted_summaries = []\n",
        "\n",
        "# Iterate over rows of the DataFrame using iterrows()\n",
        "for idx, row in eval_df.iterrows():\n",
        "    test_summary = row['Test Summaries']\n",
        "    predicted_summary = row['Predicted Summaries']\n",
        "\n",
        "    # Check if either test_summary or predicted_summary is empty or None\n",
        "    if not test_summary or not predicted_summary:\n",
        "        continue  # Skip empty or None values\n",
        "\n",
        "    # Append valid summaries to respective lists\n",
        "    test_summaries.append(test_summary)\n",
        "    predicted_summaries.append(predicted_summary)\n",
        "\n",
        "# Update DataFrame with filtered summaries\n",
        "eval_df['Test Summaries'] = test_summaries\n",
        "eval_df['Predicted Summaries'] = predicted_summaries\n",
        "\n",
        "# Display DataFrame information after filtering\n",
        "print(eval_df.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY1cXV39KOxL",
        "outputId": "8cf2653f-8467-457e-b58a-5bce152e74d1"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4998 entries, 0 to 4997\n",
            "Data columns (total 2 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   Test Summaries       4998 non-null   object\n",
            " 1   Predicted Summaries  4998 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 78.2+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "def calculate_rouge_scores(actual_summaries, predicted_summaries):\n",
        "    rouge = Rouge()\n",
        "    scores = rouge.get_scores(predicted_summaries, actual_summaries, avg=True)\n",
        "    return scores\n",
        "\n",
        "rouge_scores = calculate_rouge_scores(eval_df['Predicted Summaries'],eval_df['Test Summaries'])\n",
        "print(\"ROUGE Scores:\")\n",
        "print(rouge_scores)\n",
        "\n",
        "# Print in specified format\n",
        "print(\"ROUGE Scores - With Cleaning Text and Summary\")\n",
        "print(\"=\" * 20)\n",
        "for metric, scores in rouge_scores.items():\n",
        "    print(f\"{metric}:\")\n",
        "    print(f\"Precision: {scores['p']:.2f}\")  # Precision\n",
        "    print(f\"Recall: {scores['r']:.2f}\")     # Recall\n",
        "    print(f\"F1-Score: {scores['f']:.2f}\")    # F1-Score\n",
        "    print(\"=\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXy_GJnaLh1L",
        "outputId": "56e2cb09-9abe-4833-f574-91fd0b84c791"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE Scores:\n",
            "{'rouge-1': {'r': 0.4230503535353553, 'p': 0.42332051948052124, 'f': 0.4226614135712477}, 'rouge-2': {'r': 0.26477308080808054, 'p': 0.2637912554112551, 'f': 0.26401380395327834}, 'rouge-l': {'r': 0.4230503535353553, 'p': 0.42332051948052124, 'f': 0.4226614135712477}}\n",
            "ROUGE Scores - With Cleaning Text and Summary\n",
            "====================\n",
            "rouge-1:\n",
            "Precision: 0.42\n",
            "Recall: 0.42\n",
            "F1-Score: 0.42\n",
            "====================\n",
            "rouge-2:\n",
            "Precision: 0.26\n",
            "Recall: 0.26\n",
            "F1-Score: 0.26\n",
            "====================\n",
            "rouge-l:\n",
            "Precision: 0.42\n",
            "Recall: 0.42\n",
            "F1-Score: 0.42\n",
            "====================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "def calculate_rouge_scores(actual_summaries, predicted_summaries):\n",
        "    rouge = Rouge()\n",
        "    scores = rouge.get_scores(predicted_summaries, actual_summaries, avg=True)\n",
        "    return scores\n",
        "\n",
        "rouge_scores = calculate_rouge_scores(eval_df['Predicted Summaries'],eval_df['Test Summaries'])\n",
        "print(\"ROUGE Scores:\")\n",
        "print(rouge_scores)\n",
        "\n",
        "# Print in specified format\n",
        "print(\"ROUGE Scores - Without Cleaning Text and Summary\")\n",
        "print(\"=\" * 20)\n",
        "for metric, scores in rouge_scores.items():\n",
        "    print(f\"{metric}:\")\n",
        "    print(f\"Precision: {scores['p']:.2f}\")  # Precision\n",
        "    print(f\"Recall: {scores['r']:.2f}\")     # Recall\n",
        "    print(f\"F1-Score: {scores['f']:.2f}\")    # F1-Score\n",
        "    print(\"=\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPZBpU4R8etZ",
        "outputId": "a3b35232-436d-48ae-ec37-4932d6becdc6"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE Scores:\n",
            "{'rouge-1': {'r': 0.37920268379628763, 'p': 0.3843781977803248, 'f': 0.38031376413088885}, 'rouge-2': {'r': 0.26290339643068894, 'p': 0.2690307557993447, 'f': 0.2646454367117812}, 'rouge-l': {'r': 0.37920268379628763, 'p': 0.3843781977803248, 'f': 0.38031376413088885}}\n",
            "ROUGE Scores - Without Cleaning Text and Summary\n",
            "====================\n",
            "rouge-1:\n",
            "Precision: 0.38\n",
            "Recall: 0.38\n",
            "F1-Score: 0.38\n",
            "====================\n",
            "rouge-2:\n",
            "Precision: 0.27\n",
            "Recall: 0.26\n",
            "F1-Score: 0.26\n",
            "====================\n",
            "rouge-l:\n",
            "Precision: 0.38\n",
            "Recall: 0.38\n",
            "F1-Score: 0.38\n",
            "====================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#With Text Preprocessing\n",
        "print(\"Input Text\")\n",
        "review_text=input(\"Enter your input Text\")\n",
        "print(\"Give your actual summary\")\n",
        "actual_summary=input(\"Enter your actual summary\")\n",
        "\n",
        "\n",
        "input_text=preprocess_text(review_text)\n",
        "input_summary=preprocess_text(actual_summary)\n",
        "predicted_summary= model_infer(model, tokenizer, input_text + \" TL;DR \").split(\" TL;DR \")[1].strip()\n",
        "scores= calculate_rouge_scores([input_summary],[predicted_summary])\n",
        "\n",
        "\n",
        "print(\"Input Text:\", review_text)\n",
        "print(\"Actual Summary:\", actual_summary)\n",
        "print(\"Predicted Summary:\", predicted_summary)\n",
        "print(\"ROUGE Scores:\", scores)\n",
        "print(\"ROUGE-1: Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}\".format(scores['rouge-1']['p'], scores['rouge-1']['r'], scores['rouge-1']['f']))\n",
        "print(\"ROUGE-2: Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}\".format(scores['rouge-2']['p'], scores['rouge-2']['r'], scores['rouge-2']['f']))\n",
        "print(\"ROUGE-L: Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}\".format(scores['rouge-l']['p'], scores['rouge-l']['r'], scores['rouge-l']['f']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SofUMLY4NVfF",
        "outputId": "90224324-b767-4069-e823-3d4608e1f4f8"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text\n",
            "Enter your input TextThis tea is not expensive, but is the same full-bodied brew you get at a good Irish B&B.  m-m-m. \n",
            "Give your actual summary\n",
            "Enter your actual summaryLyon's Irish tea bags\n",
            "Input Text: This tea is not expensive, but is the same full-bodied brew you get at a good Irish B&B.  m-m-m. \n",
            "Actual Summary: Lyon's Irish tea bags\n",
            "Predicted Summary: erya krindt\n",
            "ROUGE Scores: {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "ROUGE-1: Precision: 0.00, Recall: 0.00, F1-Score: 0.00\n",
            "ROUGE-2: Precision: 0.00, Recall: 0.00, F1-Score: 0.00\n",
            "ROUGE-L: Precision: 0.00, Recall: 0.00, F1-Score: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Without Text preprocessing"
      ],
      "metadata": {
        "id": "e9ZgvwmXMLjN"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input Text\")\n",
        "review_text=input(\"Enter your input Text\")\n",
        "print(\"Give your actual summary\")\n",
        "actual_summary=input(\"Enter your actual summary\")\n",
        "\n",
        "\n",
        "input_text=review_text\n",
        "input_summary=actual_summary\n",
        "predicted_summary= model_infer(model, tokenizer, input_text + \" TL;DR \").split(\" TL;DR \")[1].strip()\n",
        "scores= calculate_rouge_scores([input_summary],[predicted_summary])\n",
        "\n",
        "\n",
        "print(\"Input Text:\", review_text)\n",
        "print(\"Actual Summary:\", actual_summary)\n",
        "print(\"Predicted Summary:\", predicted_summary)\n",
        "print(\"ROUGE Scores:\", scores)\n",
        "print(\"ROUGE-1: Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}\".format(scores['rouge-1']['p'], scores['rouge-1']['r'], scores['rouge-1']['f']))\n",
        "print(\"ROUGE-2: Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}\".format(scores['rouge-2']['p'], scores['rouge-2']['r'], scores['rouge-2']['f']))\n",
        "print(\"ROUGE-L: Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}\".format(scores['rouge-l']['p'], scores['rouge-l']['r'], scores['rouge-l']['f']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1zkIw1q4cA8",
        "outputId": "e3d748cc-e275-4803-8bb5-3649d36f3028"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text\n",
            "Enter your input TextThis tea is not expensive, but is the same full-bodied brew you get at a good Irish B&B.  m-m-m. \n",
            "Give your actual summary\n",
            "Enter your actual summary Lyon's Irish tea bags\n",
            "Input Text: This tea is not expensive, but is the same full-bodied brew you get at a good Irish B&B.  m-m-m. \n",
            "Actual Summary:  Lyon's Irish tea bags\n",
            "Predicted Summary: Tea\n",
            "ROUGE Scores: {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "ROUGE-1: Precision: 0.00, Recall: 0.00, F1-Score: 0.00\n",
            "ROUGE-2: Precision: 0.00, Recall: 0.00, F1-Score: 0.00\n",
            "ROUGE-L: Precision: 0.00, Recall: 0.00, F1-Score: 0.00\n"
          ]
        }
      ]
    }
  ]
}